Video based Action Recognition using GluonCV:

The computer vision toolkit used for video based action recognition is GluonCV which is based on Apache MXNet. This toolkit provides state-of-the-art pre-trained models for various computer vision tasks such as object detection, segmentation, pose estimation, action recognition, etc. These are lightweight and flexible building blocks that can be customized for common components for model design, training or inference. GluonCV benefits using MXNet that provides high performance C++ implementations of operators leveraged by Gluon. This toolkit can be easily deployed with minimal configuration in different programming languages.
 
This implementation uses a pre-trained TSN (Temporal Segmentation Network) from gluoncv-model-zoo to classify video frames from UCF101 dataset. This dataset is an action recognition dataset of realistic action videos taken from around 13,320 short Youtube videos consisting for 101 action classes. The pre-trained TSN model, VGG16, is used to predict action from a single videoframe (i.e. image based action recognition) as well as from multiple video frames taken from a video. 

On implementing the pretrained model on the given dataset, the model predicts the action from single video frame with 99.8% confidence and the action from the video with 97.8% confidence. Thus, this approach increases the prediction accuracy with easy configuration and implementation steps.  
